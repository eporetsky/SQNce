{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import sqlite3\n",
    "import zlib\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "from Bio import SeqIO \n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-cookbook",
   "metadata": {},
   "source": [
    "# 1. Creation the SQNce-db file with all tables \n",
    "<a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add documentation to all SQNce creation functions\n",
    "\n",
    "# Establish connection with SQNce.db, generating a new SQLite3 database if needed\n",
    "def sql_connection():\n",
    "    try:\n",
    "        con = sqlite3.connect('SQNce.db')\n",
    "        print(\"Connection established.\")\n",
    "        return(con)\n",
    "    except Error:\n",
    "        print(Error)\n",
    "\n",
    "# After establishing connection with SQNce create the specified tables\n",
    "def sql_table(con):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS species(\n",
    "                         species_name text PRIMARY KEY, \n",
    "                         common_name text) \n",
    "                         WITHOUT ROWID\"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS genotypes(\n",
    "                         genotype_id text PRIMARY KEY, \n",
    "                         species_name text, \n",
    "                         genotype_name text,\n",
    "                         FOREIGN KEY (species_name) REFERENCES species(species_name)) \n",
    "                         WITHOUT ROWID\"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_coordinates(\n",
    "                         gene_id text,\n",
    "                         genotype_id text,\n",
    "                         gene_chr text,\n",
    "                         gene_start integer,\n",
    "                         gene_end integer,\n",
    "                         gene_orientation text,\n",
    "                         FOREIGN KEY (genotype_id) REFERENCES genotypes(genotype_id)) \n",
    "                         \"\"\")\n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_symbols(\n",
    "                         gene_id text,\n",
    "                         genotype_id text,\n",
    "                         gene_symbol text,\n",
    "                         FOREIGN KEY (genotype_id) REFERENCES genotypes(genotype_id)) \n",
    "                         \"\"\")\n",
    "\n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS protein_seqs(\n",
    "                         protein_id text,\n",
    "                         species_id text,\n",
    "                         genotype_id text,\n",
    "                         protein_length text,\n",
    "                         protein_sequence blob,\n",
    "                         FOREIGN KEY (genotype_id) REFERENCES genotypes(genotype_id)) \n",
    "                         \"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_families(\n",
    "                         protein_id text,\n",
    "                         species_id text,\n",
    "                         genotype_id text,\n",
    "                         source_id text,\n",
    "                         family_id text,\n",
    "                         family_name text,\n",
    "                         FOREIGN KEY (genotype_id) REFERENCES genotypes(genotype_id)) \n",
    "    \"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS BBHs(\n",
    "                         subject_id text,\n",
    "                         query_id text,\n",
    "                         bit_score integer,\n",
    "                         subject_genotype text,\n",
    "                         query_genotype text) \n",
    "    \"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS promoter_seqs(\n",
    "                         protein_id text,\n",
    "                         genotype_id text,\n",
    "                         promoter_kind text,\n",
    "                         promoter_length text,\n",
    "                         promoter_sequence blob,\n",
    "                         FOREIGN KEY (genotype_id) REFERENCES genotypes(genotype_id)) \n",
    "                         \"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_annotations(\n",
    "                         gene_id text PRIMARY KEY,\n",
    "                         gene_species text,\n",
    "                         gene_genotype text,\n",
    "                         annotation_source text,\n",
    "                         gene_annotation text,\n",
    "                         FOREIGN KEY (gene_genotype) REFERENCES genotypes(genotype_id)) \n",
    "                         WITHOUT ROWID\"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS packages(\n",
    "                         rowid integer PRIMARY KEY,\n",
    "                         name text,\n",
    "                         version text,\n",
    "                         settings text) \n",
    "                         WITHOUT ROWID\"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS studies(\n",
    "                         study_accession text PRIMARY KEY, \n",
    "                         tax_id integer,\n",
    "                         scientific_name text,\n",
    "                         instrument_model text,\n",
    "                         library_strategy text,\n",
    "                         description text)\n",
    "                         WITHOUT ROWID\"\"\")\n",
    "\n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS fastq(\n",
    "                         run_accession text PRIMARY KEY,\n",
    "                         study_accession text,\n",
    "                         read_count integer,\n",
    "                         sample_alias text,\n",
    "                         fastq_ftp text,\n",
    "                         fastq_md5 text,\n",
    "                         compression integer,\n",
    "                         FOREIGN KEY (study_accession) REFERENCES studies(study_accession)) \n",
    "                         WITHOUT ROWID\"\"\")\n",
    "    \n",
    "    cursorObj.execute(\"\"\"CREATE TABLE IF NOT EXISTS bam(\n",
    "                         run_accession text,\n",
    "                         study_accession text,\n",
    "                         sample_alias text,\n",
    "                         compression integer,\n",
    "                         filter integer,\n",
    "                         align integer,\n",
    "                         sort integer,\n",
    "                         FOREIGN KEY (run_accession) REFERENCES fastq(run_accession)) \n",
    "                         \"\"\")\n",
    "\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current implementation requires re-parsing of all the input files to create SQNce\n",
    "# TODO SQNce update functions to parse input data only if not previously included \n",
    "if os.path.exists(\"SQNce.db\"): os.remove(\"SQNce.db\")\n",
    "con = sql_connection()\n",
    "sql_table(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-antarctica",
   "metadata": {},
   "source": [
    "# 2. Populate SQNce-db with the required data\n",
    "* SQNce database is initiated using predifined TSV files\n",
    "* TSV either contain the input data or reference input files to parse\n",
    "* TODO add documentation to SQNce data input parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-terminology",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "<a class=\"anchor\" id=\"section2\"></a>\n",
    "* [1. Creation the SQNce-db file with all tables](#section1)\n",
    "* [2. Populate SQNce-db with the required data](#section2)\n",
    "* [Insert species and genotype IDs](#genotypes)\n",
    "* [Insert gene genomic coordinates](#coordinates)\n",
    "* [Insert protein sequences](#proteins)\n",
    "* [Insert gene family annotations](#families)\n",
    "* [Insert best blast hists (BBHs)](#BBHs)\n",
    "* [Insert promoter sequences](#promoters)\n",
    "* [Gene annotation insert](#annotations)\n",
    "* [Insert gene symbols](#symbols)\n",
    "* [Insert GO Terms](#GO)\n",
    "* [Insert RNA-seq Files](#RNAseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-scenario",
   "metadata": {},
   "source": [
    "# Insert species and genotype IDs \n",
    "<a class=\"anchor\" id=\"genotypes\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genotype_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO genotypes(\n",
    "                         genotype_id, \n",
    "                         species_name, \n",
    "                         genotype_name,\n",
    "                         gene_number) \n",
    "                         VALUES(?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"init/species.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    species_insert(con, entities=list(row))\n",
    "\n",
    "# Gene number is only relevant for GO term enrichment for now\n",
    "# so I will call this function from within that function\n",
    "# Will look for a way to streamline it in the future\n",
    "# Also, should check if there are genes missing from annotation\n",
    "# input files. Maybe sequences might give a more accurate number\n",
    "#df = pd.read_csv(\"init/genotypes.tsv\", sep=\"\\t\")\n",
    "#for index, row in df.iterrows():\n",
    "#    genotype_insert(con, entities=list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-single",
   "metadata": {},
   "source": [
    "# Insert gene genomic coordinates\n",
    "<a class=\"anchor\" id=\"coordinates\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "def gene_coordinates_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO gene_coordinates(\n",
    "                         gene_id,\n",
    "                         genotype_id,\n",
    "                         gene_chr, \n",
    "                         gene_start,  \n",
    "                         gene_end,\n",
    "                         gene_orientation) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/coordinates.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    gff3_file = gzip.open(\"inputs/gff3/\"+row[3], mode='rt')\n",
    "    gene_coordinate_list = []\n",
    "    for gene in gff3_file:\n",
    "        gene = gene.split(\"\\t\")\n",
    "        if len(gene) == 1:\n",
    "            # skip the first row\n",
    "            continue\n",
    "        if gene[2] == \"gene\":\n",
    "            gene_id = gene[-1].split(\";\")\n",
    "            gene_id = [i for i in gene_id if i.startswith('Name=')][0].replace('Name=', '').replace('\\n', '') # delete \\n if exists\n",
    "            # Append list of: gene ID, genotype, chromsome, start, end, orientation\n",
    "            gene_coordinate_list.append([gene_id, row[1], gene[0], gene[3], gene[4], gene[6]])\n",
    "        else:\n",
    "            continue\n",
    "    gene_coordinates_insert(con, gene_coordinate_list)    \n",
    "\n",
    "# Create a secondary key on the name column\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX coordinate_index_start ON gene_coordinates(genotype_id, gene_chr, gene_start)\")\n",
    "cursorObj.execute(\"CREATE INDEX coordinate_index_end ON gene_coordinates(genotype_id, gene_chr, gene_end)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-ethnic",
   "metadata": {},
   "source": [
    "# Insert protein sequences\n",
    "<a class=\"anchor\" id=\"proteins\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "def protein_seq_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO protein_seqs(\n",
    "                         protein_id,\n",
    "                         species_id,\n",
    "                         genotype_id, \n",
    "                         protein_length,  \n",
    "                         protein_sequence) \n",
    "                         VALUES(?, ?, ?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/proteins.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fasta_file = gzip.open(\"inputs/proteins/\"+row[2], mode='rt')\n",
    "    protein_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        protein_seq_list.append([seq.id, row[0], row[1], len(seq.seq), \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    protein_seq_insert(con, protein_seq_list)\n",
    "# Create keys for protein IDs with isoform and without\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX proteins_ids_index ON protein_seqs(protein_id)\")\n",
    "con.commit()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-estate",
   "metadata": {},
   "source": [
    "# Insert gene family annotations\n",
    "<a class=\"anchor\" id=\"families\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_annotation_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO gene_families(\n",
    "                         protein_id,\n",
    "                         species_id,\n",
    "                         genotype_id,\n",
    "                         source_id,\n",
    "                         family_id,  \n",
    "                         family_name) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/families.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    annot = pd.read_csv(\"inputs/families/\"+row[3], sep=\"\\t\")\n",
    "    annot.insert(1, 'species', row[0])\n",
    "    annot.insert(2, 'genotype', row[1])\n",
    "    annot.insert(3, 'source', row[2])\n",
    "    family_annotation_insert(con, annot.values.tolist())\n",
    "# Create keys for protein IDs with isoform and without\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX family_gene_index ON gene_families(protein_id)\")\n",
    "#cursorObj.execute(\"CREATE INDEX family_species_index ON gene_families(species_id)\")\n",
    "#cursorObj.execute(\"CREATE INDEX family_genotype_index ON gene_families(genotype_id)\")\n",
    "#cursorObj.execute(\"CREATE INDEX family_id_index ON gene_families(family_id)\")\n",
    "cursorObj.execute(\"CREATE INDEX family_name_index ON gene_families(family_name)\")\n",
    "cursorObj.execute(\"CREATE INDEX family_genotype_name_index ON gene_families(genotype_id, family_name)\")\n",
    "con.commit()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-technology",
   "metadata": {},
   "source": [
    "# Insert best blast hists (BBHs)\n",
    "<a class=\"anchor\" id=\"BBHs\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBHs_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO BBHs(\n",
    "                         subject_id,\n",
    "                         query_id,\n",
    "                         bit_score,\n",
    "                         subject_genotype,\n",
    "                         query_genotype) \n",
    "                         VALUES(?, ?, ?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/BBHs_files.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    bbh_df = pd.read_csv(\"inputs/BBHs/\"+row[2], sep=\"\\t\")\n",
    "    BBHs_insert(con, bbh_df.values.tolist())\n",
    "# Create keys for subject and query gene IDs\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX BBHs_subject_index ON BBHs(subject_id)\")\n",
    "cursorObj.execute(\"CREATE INDEX BBHs_query_index ON BBHs(query_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-milwaukee",
   "metadata": {},
   "source": [
    "# Insert promoter sequences\n",
    "<a class=\"anchor\" id=\"promoters\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "def promoter_seq_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO promoter_seqs(\n",
    "                         protein_id,\n",
    "                         genotype_id,\n",
    "                         promoter_kind,\n",
    "                         promoter_length,  \n",
    "                         promoter_sequence) \n",
    "                         VALUES(?, ?, ?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/promoters.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fasta_file = gzip.open(\"inputs/promoters/\"+row[5]+\"_1kb_ATG.fasta.gz\", mode='rt')\n",
    "    promoter_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # TODO change db to number key to avoid duplicated name problems\n",
    "        if row[0] == \"ZmB73v3\": \n",
    "            seq.id = seq.id + \"v3\"\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        promoter_seq_list.append([seq.id, row[0], \"ATG\", row[4], \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    promoter_seq_insert(con, promoter_seq_list)\n",
    "    \n",
    "    fasta_file = gzip.open(\"inputs/promoters/\"+row[5]+\"_1kb_TSS.fasta.gz\", mode='rt')\n",
    "    promoter_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # TODO change db to number key to avoid duplicated name problems\n",
    "        if row[0] == \"ZmB73v3\": \n",
    "            seq.id = seq.id + \"v3\"\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        promoter_seq_list.append([seq.id, row[0], \"TSS\", row[4], \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    promoter_seq_insert(con, promoter_seq_list)\n",
    "    \n",
    "# Create a secondary key on the name column\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX promoter_index ON promoter_seqs(protein_id, promoter_kind)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-antigua",
   "metadata": {},
   "source": [
    "# Gene annotation insert\n",
    "<a class=\"anchor\" id=\"annotations\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_annotation_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO gene_annotations(\n",
    "                         gene_id,\n",
    "                         gene_species,\n",
    "                         gene_genotype,\n",
    "                         annotation_source,\n",
    "                         gene_annotation) \n",
    "                         VALUES(?, ?, ?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "    \n",
    "df = pd.read_csv(\"init/annotation_list.tsv\", sep=\"\\t\")\n",
    "# Every element is: gene_id, gene_species, gene_genotype, gene_annotation, annotation_source\n",
    "gene_annotation_list = []\n",
    "for index, row in df.iterrows():\n",
    "    annot = pd.read_csv(\"inputs/annotations/\"+row[3], sep=\"\\t\")\n",
    "    annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "    if row[0]==\"Arabidopsis thaliana\":\n",
    "        annot = annot[[\"locusName\", \"rice-defline\"]]\n",
    "    elif row[0] in [\"Panicum hallii\", \"Pharus latifolius\", \"Solanum lycopersicum\", \"Vigna unguiculata\"]:\n",
    "        annot = annot[[\"locusName\", \"Best-hit-arabi-defline\"]]        \n",
    "    else:\n",
    "        annot = annot[[\"locusName\", \"arabi-defline\"]]\n",
    "    annot.insert(1, 'species', row[0])\n",
    "    annot.insert(2, 'genotype', row[1])\n",
    "    annot.insert(3, 'source', row[2])\n",
    "    gene_annotation_insert(con, annot.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-helmet",
   "metadata": {},
   "source": [
    "# Insert gene symbols\n",
    "<a class=\"anchor\" id=\"symbols\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_symbols_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO gene_symbols(\n",
    "                         gene_id,\n",
    "                         genotype_id,\n",
    "                         gene_symbol) \n",
    "                         VALUES(?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/symbols_list.tsv\", sep=\"\\t\")\n",
    "# Every element is: gene_id, gene_species, gene_genotype, gene_annotation, annotation_source\n",
    "gene_annotation_list = []\n",
    "for index, row in df.iterrows():\n",
    "    annot = pd.read_csv(\"inputs/symbols/\"+row[2], sep=\"\\t\")\n",
    "    #annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "    annot.insert(1, 'gene_id', row[0])\n",
    "    #print(annot.values.tolist())\n",
    "    gene_symbols_insert(con, annot.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-business",
   "metadata": {},
   "source": [
    "# Insert GO Terms\n",
    "<a class=\"anchor\" id=\"GO\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_symbols_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.executemany(\"\"\"INSERT INTO gene_GOs(\n",
    "                         gene_id,\n",
    "                         genotype_id,\n",
    "                         GO_id) \n",
    "                         VALUES(?, ?, ?)\"\"\", entity_list)\n",
    "    con.commit()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"init/GO_files.tsv\", sep=\"\\t\")\n",
    "\n",
    "for row in df.values:\n",
    "    # Check annotation column\n",
    "    long_list = [] # have a row for each gene-GO combination\n",
    "    if row[2] == \"Phytozome\": # currently only support phytozome GO annotations\n",
    "        annot = pd.read_csv(\"inputs/annotations/\"+row[3], sep=\"\\t\")[['locusName', 'GO']]\n",
    "        # I am assuming that all variants have the same GO term but should double check\n",
    "        annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "        # https://stackoverflow.com/questions/41244981/how-to-extract-comma-separated-values-to-individual-rows-in-pandas\n",
    "        annot = annot.set_index('locusName').GO.str.split(',', expand=True).stack().reset_index('locusName')\n",
    "    break\n",
    "    # genotype_id, species_name, genotype_name, gene_number\n",
    "    genotype_insert(con, entities=[row[0], row[1],])\n",
    "    annot\n",
    "    #annot.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_dict = {}\n",
    "for row in range(len(gene_go_terms)):\n",
    "    for go_term in gene_go_terms.iloc[row][1].split(\",\"):\n",
    "        if go_term not in go_dict.keys():\n",
    "            go_dict[go_term] = [gene_go_terms.iloc[row][0]]\n",
    "        else:\n",
    "            go_dict[go_term].append(gene_go_terms.iloc[row][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-remove",
   "metadata": {},
   "source": [
    "# Insert RNA-seq Files\n",
    "<a class=\"anchor\" id=\"RNAseq\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def packages_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO packages(\n",
    "                         rowid, \n",
    "                         name,\n",
    "                         version,\n",
    "                         settings) \n",
    "                         VALUES(?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "    \n",
    "def studies_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO studies(\n",
    "                         study_accession, \n",
    "                         tax_id, \n",
    "                         scientific_name,\n",
    "                         instrument_model,\n",
    "                         library_strategy,\n",
    "                         description) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "\n",
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "def fastq_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO fastq(\n",
    "                         run_accession, \n",
    "                         study_accession, \n",
    "                         read_count, \n",
    "                         sample_alias,  \n",
    "                         fastq_ftp,\n",
    "                         fastq_md5,\n",
    "                         compression) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "    \n",
    "def bam_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO bam(\n",
    "                         run_accession,\n",
    "                         study_accession,\n",
    "                         sample_alias,\n",
    "                         compression,\n",
    "                         filter,\n",
    "                         align,\n",
    "                         sort) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/packages.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    packages_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/studies.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    studies_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/fastq.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fastq_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/bam.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    bam_insert(con, entities=list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-marker",
   "metadata": {},
   "source": [
    "# SQNce Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = \"\"\"Chr2\\t12345\\nChr3\\t54354\\nChr2\\t5234354\\n\"\"\".split(\"\\n\")\n",
    "coordinate_list = [row.split(\"\\t\") for row in rows]\n",
    "if coordinate_list[-1]==[\"\"]:\n",
    "    coordinate_list = coordinate_list[:-1]\n",
    "for row in coordinate_list:\n",
    "    if len(row) != 2:\n",
    "        return(html.P(\"Number of columns is not 2. Use tab-seperated values.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find neighboring genes\n",
    "def get_SNP_neighbors(genotype, chromsome, coordinate, distance):\n",
    "    con = sqlite3.connect('SQNce.db')\n",
    "    cursorObj = con.cursor()\n",
    "    df = pd.read_sql_query('''SELECT * \n",
    "                     FROM gene_coordinates \n",
    "                     WHERE genotype_id = \"{0}\"\n",
    "                     AND gene_chr = \"{1}\"\n",
    "                     AND gene_start BETWEEN {2} AND {3}\n",
    "                     \n",
    "                     UNION ALL\n",
    "                     \n",
    "                     SELECT * \n",
    "                     FROM gene_coordinates \n",
    "                     WHERE genotype_id = \"{0}\"\n",
    "                     AND gene_chr = \"{1}\"\n",
    "                     AND gene_start BETWEEN {2} AND {3}\n",
    "                     '''.format(genotype, chromsome, coordinate-distance, coordinate+distance), con)\n",
    "    # Should check why it returns the same row twice, probably need to correct the query\n",
    "    df = df.drop_duplicates()\n",
    "    df.insert(0, 'Query', pd.Series([\"_\".join([chromsome, str(coordinate)]) for x in range(len(df.index))]))\n",
    "    return(df)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for entity in [[\"Chr2\", 19681637], [\"Chr2\", 1234564], [\"Chr4\", 1234564], [\"Chr2\", 19681638]]:\n",
    "      df = pd.concat([df, get_SNP_neighbors(\"Arabidopsis\", entity[0], entity[1], 10000)])  \n",
    "#df.drop_duplicates(subset=[\"gene_id\"]).reset_index()\n",
    "#df1 = get_SNP_neighbors(\"Arabidopsis\", \"Chr2\", 19681637, 10000)\n",
    "#df1\n",
    "#pd.concat([df1, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find neighboring genes and annotate them\n",
    "\n",
    "df[\"annotation\"] = annotation_select(con, df[\"gene_id\"].to_list())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_available_species(con):\n",
    "    con = sqlite3.connect('SQNce.db')\n",
    "    cursorObj = con.cursor()\n",
    "    return(pd.read_sql_query(\"SELECT * FROM species\", con))\n",
    "\n",
    "show_available_species(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-incentive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursorObj = con.cursor()\n",
    "cursorObj.execute('''SELECT gene_id, gene_annotation \n",
    "                     FROM gene_annotations \n",
    "                     WHERE gene_id =  ?  ''', (entity,))\n",
    "# (name,) - need the comma to treat it as a single item and not list of letters\n",
    "selected = cursorObj.fetchall()[0]\n",
    "od[selected[0]] = selected[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add documentation to SQNce queries\n",
    "\n",
    "def protein_seq_select(con, entity_list):\n",
    "    od = OrderedDict()\n",
    "    for entity in entity_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT protein_variant, gene_annotation \n",
    "                             FROM protein_seqs \n",
    "                             WHERE protein_variant =  ?  ''', (entity,))\n",
    "        # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "        selected = cursorObj.fetchall()[0]\n",
    "        record = SeqRecord(Seq(zlib.decompress(selected[1]).decode(encoding='UTF-8')), \n",
    "                           id=selected[0], name=\"\", description=\"\")\n",
    "        od[selected[0]] = record\n",
    "        with open(\"selected.fasta\", 'w') as handle:\n",
    "            SeqIO.write(od.values(), handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_select(con, entity_list):\n",
    "    ls = []\n",
    "    for entity in entity_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT gene_id, gene_annotation \n",
    "                             FROM gene_annotations \n",
    "                             WHERE gene_id =  ?  ''', (entity,))\n",
    "        # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "        selected = cursorObj.fetchall()\n",
    "        if selected == []:\n",
    "            ls.append(\"Gene not found\")\n",
    "        else:\n",
    "            ls.append(selected[0][1])    \n",
    "    return(ls)\n",
    "\n",
    "con = sqlite3.connect('SQNce.db')\n",
    "gene_list = [\"Zm00001d010294\", \"dsa\", \"Sobic.002G128101\", \"AT2G34360\", \"Sobic.002G128101\", \"002G128101\"]\n",
    "df = pd.DataFrame({\"name\": gene_list, \"annotation\": annotation_select(con, gene_list) })\n",
    "df.columns = [\"GeneID\", \"annotation\"]\n",
    "df\n",
    "#pd.DataFrame.from_dict(annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"], \"dict\"), \n",
    "#                       orient=\"index\", columns=[\"annotation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"]), \n",
    "                              orient=\"index\").reset_index()\n",
    "test.columns = [\"GeneID\", \"annotation\"]\n",
    "test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-treasure",
   "metadata": {},
   "source": [
    "# Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('SQNce.db')\n",
    "# Use the above query functions to parse SQNce with your gene lists \n",
    "input_value = [your_gene_list]\n",
    "protein_seq_select(con, input_value)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{ 'label': label, 'value': val} for label, val in [[1,2], [2,3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_db_vals(db, table, column, custom_vals=[], return_ls=False):\n",
    "    # Input is the column to select and from which table\n",
    "    # Returns a list of all values in a specific table from SQNce.db\n",
    "    # Custom vals are added to the front using nested list of [label, value]\n",
    "    ls = [{ 'label': label, 'value': val} for label, val in custom_vals]\n",
    "    con = sqlite3.connect(db) # deploy with this\n",
    "    cursorObj = con.cursor()\n",
    "    distinct_df = pd.read_sql_query('''SELECT DISTINCT {0} \n",
    "                                       FROM {1}'''.format(column, table), con)\n",
    "    if return_ls:\n",
    "            return(distinct_df[column].to_list())\n",
    "    for name in distinct_df[column]:\n",
    "        ls.append({'label': name, 'value': name})\n",
    "    return(ls)\n",
    "distinct_db_vals(\"SQNce.db\", \"gene_coordinates\", \"genotype_id\",[[1,2], [2,3]], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_gene_select(gene_list):\n",
    "    # Use an input list of genes to find their family assignments\n",
    "    con = sqlite3.connect(\"SQNce.db\")\n",
    "    ls = []\n",
    "    for gene in gene_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT protein_id, family_name \n",
    "                            FROM gene_families\n",
    "                            WHERE protein_id =  ? ''', (gene,))\n",
    "        selected = cursorObj.fetchall()\n",
    "        if selected == []:\n",
    "            ls.append(\"Gene not found\")\n",
    "        else:\n",
    "            ls.append(selected[0][1])    \n",
    "    return(ls)\n",
    "family_gene_select([\"Seita.5G010100\", \"test\", \"Zm00001d011673\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"SQNce.db\") # deploy with this\n",
    "cursorObj = con.cursor()\n",
    "genotype = str(\"','\".join(['Zea mays', \"dsa\",'Setaria italica']))\n",
    "family = str(\"','\".join(['Terpenoid synthases', 'Cytochrome P450']))\n",
    "df = pd.read_sql_query(\"\"\"SELECT protein_id, family_name \n",
    "                                   FROM gene_families\n",
    "                                   WHERE species_id IN ('{0}') AND family_name IN ('{1}')\"\"\".format(genotype, family), con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = \"subject_id\"\n",
    "entity_list = [\"Zm00001d014121\", \"Zm00001d014134, \"\"Zm00001d014136\"]\n",
    "con = sqlite3.connect(\"SQNce.db\") # deploy with this\n",
    "cursorObj = con.cursor()\n",
    "entity_list_str = str(\"','\".join(entity_list))\n",
    "df = pd.read_sql_query(\"\"\"SELECT * \n",
    "                        FROM BBHs\n",
    "                        WHERE {0} IN ('{1}')\"\"\".format(selected, entity_list_str), con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a stupid function but it seems to work correctly.\n",
    "df.sort_values(['bit_score'], ascending=False).groupby([\"subject_id\", \"query_genotype\"]).agg({\"bit_score\": \"first\", \"query_id\": \"first\",}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-paragraph",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df[\"query_genotype\"].isin([\"B97\", \"dsa\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(\"init/BBHs_combs.tsv\"), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-commission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
