{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supposed-large",
   "metadata": {},
   "source": [
    "# 1. Creation the SQNce-db file with all tables \n",
    "<a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import sqlite3\n",
    "import zlib\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "from Bio import SeqIO \n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "headed-vancouver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "# Current implementation requires re-parsing of all the input files to create SQNce\n",
    "# TODO SQNce update functions to parse input data only if not previously included \n",
    "\n",
    "# Establish connection with SQNce.db, generating a new SQLite3 database if needed\n",
    "def sql_connection():\n",
    "    try:\n",
    "        con = sqlite3.connect('SQNce.db')\n",
    "        print(\"Connection established.\")\n",
    "        return(con)\n",
    "    except Error:\n",
    "        print(Error)\n",
    "\n",
    "# if os.path.exists(\"SQNce.db\"): os.remove(\"SQNce.db\")\n",
    "con = sql_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-button",
   "metadata": {},
   "source": [
    "# 2. Populate SQNce-db with the required data\n",
    "* SQNce database is initiated using predifined TSV files\n",
    "* TSV either contain the input data or reference input files to parse\n",
    "* TODO add documentation to SQNce data input parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-milwaukee",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "<a class=\"anchor\" id=\"section2\"></a>\n",
    "* [1. Creation the SQNce-db file with all tables](#section1)\n",
    "* [2. Populate SQNce-db with the required data](#section2)\n",
    "* [Insert species and genotype IDs](#genotypes)\n",
    "* [Insert gene genomic coordinates](#coordinates)\n",
    "* [Insert protein sequences](#proteins)\n",
    "* [Insert gene family annotations](#families)\n",
    "* [Insert best blast hists (BBHs)](#BBHs)\n",
    "* [Insert promoter sequences](#promoters)\n",
    "* [Gene annotation insert](#annotations)\n",
    "* [Insert gene symbols](#symbols)\n",
    "* [Insert GO Terms](#GO)\n",
    "* [Insert RNA-seq Files](#RNAseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-gilbert",
   "metadata": {},
   "source": [
    "# Insert species and genotype IDs \n",
    "<a class=\"anchor\" id=\"genotypes\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "appreciated-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"init/species.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    #print(list(row))\n",
    "    #species_insert(con, entities=list(row))\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-relations",
   "metadata": {},
   "source": [
    "# Insert GO Terms\n",
    "<a class=\"anchor\" id=\"GO\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latin-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS genomes(\n",
    "                     genome_id text,\n",
    "                     species_name text,\n",
    "                     genotype_id text,\n",
    "                     source_id text,\n",
    "                     file_name text,\n",
    "                     gene_number integer)\"\"\")\n",
    "con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/genomes.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    row = list(row)\n",
    "    # If from phytozome use the annotation table to read number of genes\n",
    "    if row[3] == \"Phytozome\":\n",
    "        annot = pd.read_csv(\"inputs/annotations/\"+row[4], sep=\"\\t\")\n",
    "        annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "        con.cursor().execute(\"\"\"INSERT INTO genomes(\n",
    "                             genome_id, species_name, genotype_id,\n",
    "                             source_id, file_name, gene_number) \n",
    "                             VALUES(?, ?, ?, ?, ?, ?)\"\"\", row+[annot.shape[0]])\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "incorporate-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the GO database OBO file to keep the GO annotations\n",
    "df = pd.read_csv(\"inputs/GO/go-basic.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df.columns = [\"GO_id\", \"GO_short\", \"process\", \"GO_long\"]\n",
    "df.to_sql('GO_basic', con, if_exists='replace', index=False)\n",
    "\n",
    "con.cursor().execute(\"CREATE INDEX GO_basic_id ON GO_basic(GO_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS genomes(\n",
    "                     genome_id text,\n",
    "                     species_name text,\n",
    "                     genotype_id text,\n",
    "                     source_id text,\n",
    "                     file_name text,\n",
    "                     gene_number integer)\"\"\")\n",
    "con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/genomes.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    row = list(row)\n",
    "    # If from phytozome use the annotation table to read number of genes\n",
    "    if row[3] == \"Phytozome\":\n",
    "        annot = pd.read_csv(\"inputs/annotations/\"+row[4], sep=\"\\t\")\n",
    "        annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "        con.cursor().execute(\"\"\"INSERT INTO genomes(\n",
    "                             genome_id, species_name, genotype_id,\n",
    "                             source_id, file_name, gene_number) \n",
    "                             VALUES(?, ?, ?, ?, ?, ?)\"\"\", row+[annot.shape[0]])\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "criminal-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_GOs(\n",
    "                     gene_id text, \n",
    "                     GO_id text, \n",
    "                     GO_count integer,\n",
    "                     genome_id text,\n",
    "                     source_id text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/GO_files.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    # Check annotation column\n",
    "    long_list = [] # have a row for each gene-GO combination\n",
    "    if row[2] == \"Phytozome\": # currently only support phytozome GO annotations\n",
    "        annot = pd.read_csv(\"inputs/annotations/\"+row[3], sep=\"\\t\")[['locusName', 'GO']]\n",
    "        # I am assuming that all variants have the same GO term but should double check\n",
    "        annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "        # https://stackoverflow.com/questions/41244981/how-to-extract-comma-separated-values-to-individual-rows-in-pandas\n",
    "        annot = annot.set_index('locusName').GO.str.split(',', expand=True).stack().reset_index('locusName')\n",
    "        annot.columns = [\"gene_id\", \"GO\"]\n",
    "        annot = annot.merge(annot.groupby(\"GO\").count().reset_index(), on=\"GO\", how=\"left\")\n",
    "        annot[\"genome_id\"] = row[0]\n",
    "        annot[\"source_id\"] = row[2]\n",
    "\n",
    "        con.cursor().executemany(\"\"\"INSERT INTO gene_GOs(\n",
    "                                 gene_id, GO_id, GO_count, genome_id, source_id)  \n",
    "                                 VALUES(?,?,?,?,?)\"\"\", annot.values.tolist())\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-dylan",
   "metadata": {},
   "source": [
    "# Insert gene genomic coordinates\n",
    "<a class=\"anchor\" id=\"coordinates\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "iraqi-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_coordinates(\n",
    "                     gene_id text,\n",
    "                     genome_id text,\n",
    "                     gene_chr text,\n",
    "                     gene_start integer,\n",
    "                     gene_end integer,\n",
    "                     gene_orientation text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/coordinates.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    gff3_file = gzip.open(\"inputs/gff3/\"+row[3], mode='rt')\n",
    "    gene_coordinate_list = []\n",
    "    for gene in gff3_file:\n",
    "        gene = gene.split(\"\\t\")\n",
    "        if len(gene) == 1:\n",
    "            # skip the first row\n",
    "            continue\n",
    "        if gene[2] == \"gene\":\n",
    "            gene_id = gene[-1].split(\";\")\n",
    "            gene_id = [i for i in gene_id if i.startswith('Name=')][0].replace('Name=', '').replace('\\n', '') # delete \\n if exists\n",
    "            # Append list of: gene ID, genotype, chromsome, start, end, orientation\n",
    "            gene_coordinate_list.append([gene_id, row[1], gene[0], gene[3], gene[4], gene[6]])\n",
    "        else:\n",
    "            continue\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_coordinates(\n",
    "                         gene_id, genome_id, gene_chr, \n",
    "                         gene_start, gene_end, gene_orientation) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", gene_coordinate_list)\n",
    "\n",
    "# Create a secondary key on the name column\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX coordinate_index_start ON gene_coordinates(genome_id, gene_chr, gene_start)\")\n",
    "cursorObj.execute(\"CREATE INDEX coordinate_index_end ON gene_coordinates(genome_id, gene_chr, gene_end)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-companion",
   "metadata": {},
   "source": [
    "# Insert protein sequences\n",
    "<a class=\"anchor\" id=\"proteins\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stunning-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS protein_seqs(\n",
    "                     protein_id text,\n",
    "                     species_id text,\n",
    "                     genome_id text,\n",
    "                     protein_length text,\n",
    "                     protein_sequence blob)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/proteins.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fasta_file = gzip.open(\"inputs/proteins/\"+row[2], mode='rt')\n",
    "    protein_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        protein_seq_list.append([seq.id, row[0], row[1], len(seq.seq), \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO protein_seqs(\n",
    "                     protein_id, species_id, genome_id, \n",
    "                     protein_length, protein_sequence) \n",
    "                     VALUES(?, ?, ?, ?, ?)\"\"\", protein_seq_list)\n",
    "\n",
    "# Create keys for protein IDs with isoform and without\n",
    "con.cursor().execute(\"CREATE INDEX proteins_ids_index ON protein_seqs(protein_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-message",
   "metadata": {},
   "source": [
    "# Insert gene family annotations\n",
    "<a class=\"anchor\" id=\"families\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "described-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_families(\n",
    "                     protein_id text,\n",
    "                     species_id text,\n",
    "                     genome_id text,\n",
    "                     source_id text,\n",
    "                     family_id text,\n",
    "                     family_name text)\"\"\")\n",
    "\n",
    "\n",
    "def family_annotation_insert(con, entity_list):\n",
    "    cursorObj = con.cursor()\n",
    "    \n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/families.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    annot = pd.read_csv(\"inputs/families/\"+row[3], sep=\"\\t\")\n",
    "    annot.insert(1, 'species', row[0])\n",
    "    annot.insert(2, 'genome', row[1])\n",
    "    annot.insert(3, 'source', row[2])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_families(\n",
    "                         protein_id, species_id, genome_id,\n",
    "                         source_id, family_id, family_name) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", annot.values.tolist())\n",
    "# Create keys for protein IDs with isoform and without\n",
    "con.cursor().execute(\"CREATE INDEX family_gene_index ON gene_families(protein_id)\")\n",
    "#cursorObj.execute(\"CREATE INDEX family_species_index ON gene_families(species_id)\")\n",
    "#cursorObj.execute(\"CREATE INDEX family_genotype_index ON gene_families(genotype_id)\")\n",
    "#cursorObj.execute(\"CREATE INDEX family_id_index ON gene_families(family_id)\")\n",
    "con.cursor().execute(\"CREATE INDEX family_name_index ON gene_families(family_name)\")\n",
    "con.cursor().execute(\"CREATE INDEX family_genotype_name_index ON gene_families(genome_id, family_name)\")\n",
    "con.commit()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-interim",
   "metadata": {},
   "source": [
    "# Insert best blast hists (BBHs)\n",
    "<a class=\"anchor\" id=\"BBHs\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "insured-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS BBHs(\n",
    "                     subject_id text,\n",
    "                     query_id text,\n",
    "                     bit_score integer,\n",
    "                     subject_genome text,\n",
    "                     query_genome text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/BBHs_files.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    bbh_df = pd.read_csv(\"inputs/BBHs/\"+row[2], sep=\"\\t\")\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO BBHs(\n",
    "                     subject_id, query_id, bit_score,\n",
    "                     subject_genome, query_genome) \n",
    "                     VALUES(?, ?, ?, ?, ?)\"\"\", bbh_df.values.tolist())\n",
    "\n",
    "# Create keys for subject and query gene IDs\n",
    "con.cursor().execute(\"CREATE INDEX BBHs_subject_index ON BBHs(subject_id)\")\n",
    "con.cursor().execute(\"CREATE INDEX BBHs_query_index ON BBHs(query_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-stopping",
   "metadata": {},
   "source": [
    "# Insert promoter sequences\n",
    "<a class=\"anchor\" id=\"promoters\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "saved-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS promoter_seqs(\n",
    "                     protein_id text,\n",
    "                     genome_id text,\n",
    "                     promoter_kind text,\n",
    "                     promoter_length text,\n",
    "                     promoter_sequence blob)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/promoters.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fasta_file = gzip.open(\"inputs/promoters/\"+row[5]+\"_1kb_ATG.fasta.gz\", mode='rt')\n",
    "    promoter_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # TODO change db to number key to avoid duplicated name problems\n",
    "        if row[0] == \"ZmB73v3\": \n",
    "            seq.id = seq.id + \"v3\"\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        promoter_seq_list.append([seq.id, row[0], \"ATG\", row[4], \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO promoter_seqs(\n",
    "                     protein_id, genome_id, promoter_kind,\n",
    "                     promoter_length, promoter_sequence) \n",
    "                     VALUES(?, ?, ?, ?, ?)\"\"\", promoter_seq_list)\n",
    "    \n",
    "    fasta_file = gzip.open(\"inputs/promoters/\"+row[5]+\"_1kb_TSS.fasta.gz\", mode='rt')\n",
    "    promoter_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # TODO change db to number key to avoid duplicated name problems\n",
    "        if row[0] == \"ZmB73v3\": \n",
    "            seq.id = seq.id + \"v3\"\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        promoter_seq_list.append([seq.id, row[0], \"TSS\", row[4], \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO promoter_seqs(\n",
    "                     protein_id, genome_id, promoter_kind,\n",
    "                     promoter_length, promoter_sequence) \n",
    "                     VALUES(?, ?, ?, ?, ?)\"\"\", promoter_seq_list)\n",
    "\n",
    "con.cursor().execute(\"CREATE INDEX promoter_index ON promoter_seqs(protein_id, promoter_kind)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-passion",
   "metadata": {},
   "source": [
    "# Gene annotation insert\n",
    "<a class=\"anchor\" id=\"annotations\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unique-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_annotations(\n",
    "                     gene_id text PRIMARY KEY,\n",
    "                     genome_id text,\n",
    "                     gene_genotype text,\n",
    "                     annotation_source text,\n",
    "                     gene_annotation text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/annotation_list.tsv\", sep=\"\\t\")\n",
    "# Every element is: gene_id, gene_species, gene_genotype, gene_annotation, annotation_source\n",
    "gene_annotation_list = []\n",
    "for index, row in df.iterrows():\n",
    "    annot = pd.read_csv(\"inputs/annotations/\"+row[3], sep=\"\\t\")\n",
    "    annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "    if row[0]==\"Arabidopsis thaliana\":\n",
    "        annot = annot[[\"locusName\", \"rice-defline\"]]\n",
    "    elif row[0] in [\"Panicum hallii\", \"Pharus latifolius\", \"Solanum lycopersicum\", \"Vigna unguiculata\"]:\n",
    "        annot = annot[[\"locusName\", \"Best-hit-arabi-defline\"]]        \n",
    "    else:\n",
    "        annot = annot[[\"locusName\", \"arabi-defline\"]]\n",
    "    annot.insert(1, 'species', row[0])\n",
    "    annot.insert(2, 'genotype', row[1])\n",
    "    annot.insert(3, 'source', row[2])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_annotations(\n",
    "                         gene_id, genome_id, gene_genotype,\n",
    "                         annotation_source, gene_annotation) \n",
    "                         VALUES(?, ?, ?, ?, ?)\"\"\", annot.values.tolist())\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-employment",
   "metadata": {},
   "source": [
    "# Insert gene symbols\n",
    "<a class=\"anchor\" id=\"symbols\"></a>\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handy-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_symbols(\n",
    "                     gene_id text,\n",
    "                     genome_id text,\n",
    "                     gene_symbol text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/symbols_list.tsv\", sep=\"\\t\")\n",
    "# Every element is: gene_id, gene_species, gene_genotype, gene_annotation, annotation_source\n",
    "gene_annotation_list = []\n",
    "for index, row in df.iterrows():\n",
    "    annot = pd.read_csv(\"inputs/symbols/\"+row[2], sep=\"\\t\")\n",
    "    annot.insert(1, 'gene_id', row[0])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_symbols(\n",
    "                             gene_id, genome_id, gene_symbol) \n",
    "                             VALUES(?, ?, ?)\"\"\", annot.values.tolist())\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-surgeon",
   "metadata": {},
   "source": [
    "# Insert RNA-seq Files\n",
    "<a class=\"anchor\" id=\"RNAseq\"></a>\n",
    "* [Go back to section 2](#section2)\n",
    "\n",
    "(Note: This part will need more work and is not currently in use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS packages(\n",
    "                     rowid integer,\n",
    "                     name text,\n",
    "                     version text,\n",
    "                     settings text)\"\"\")\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS studies(\n",
    "                     study_accession text, \n",
    "                     tax_id integer,\n",
    "                     scientific_name text,\n",
    "                     instrument_model text,\n",
    "                     library_strategy text,\n",
    "                     description text)\"\"\")\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS fastq(\n",
    "                     run_accession text,\n",
    "                     study_accession text,\n",
    "                     read_count integer,\n",
    "                     sample_alias text,\n",
    "                     fastq_ftp text,\n",
    "                     fastq_md5 text,\n",
    "                     compression integer)\"\"\")\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS bam(\n",
    "                     run_accession text,\n",
    "                     study_accession text,\n",
    "                     sample_alias text,\n",
    "                     compression integer,\n",
    "                     filter integer,\n",
    "                     align integer,\n",
    "                     sort integer)\"\"\")\n",
    "\n",
    "def packages_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO packages(\n",
    "                         rowid, \n",
    "                         name,\n",
    "                         version,\n",
    "                         settings) \n",
    "                         VALUES(?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "    \n",
    "def studies_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO studies(\n",
    "                         study_accession, \n",
    "                         tax_id, \n",
    "                         scientific_name,\n",
    "                         instrument_model,\n",
    "                         library_strategy,\n",
    "                         description) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "\n",
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "def fastq_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO fastq(\n",
    "                         run_accession, \n",
    "                         study_accession, \n",
    "                         read_count, \n",
    "                         sample_alias,  \n",
    "                         fastq_ftp,\n",
    "                         fastq_md5,\n",
    "                         compression) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "    \n",
    "def bam_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO bam(\n",
    "                         run_accession,\n",
    "                         study_accession,\n",
    "                         sample_alias,\n",
    "                         compression,\n",
    "                         filter,\n",
    "                         align,\n",
    "                         sort) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/packages.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    packages_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/studies.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    studies_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/fastq.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fastq_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/bam.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    bam_insert(con, entities=list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-kinase",
   "metadata": {},
   "source": [
    "# SQNce Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = \"\"\"Chr2\\t12345\\nChr3\\t54354\\nChr2\\t5234354\\n\"\"\".split(\"\\n\")\n",
    "coordinate_list = [row.split(\"\\t\") for row in rows]\n",
    "if coordinate_list[-1]==[\"\"]:\n",
    "    coordinate_list = coordinate_list[:-1]\n",
    "for row in coordinate_list:\n",
    "    if len(row) != 2:\n",
    "        return(html.P(\"Number of columns is not 2. Use tab-seperated values.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find neighboring genes\n",
    "def get_SNP_neighbors(genotype, chromsome, coordinate, distance):\n",
    "    con = sqlite3.connect('SQNce.db')\n",
    "    cursorObj = con.cursor()\n",
    "    df = pd.read_sql_query('''SELECT * \n",
    "                     FROM gene_coordinates \n",
    "                     WHERE genotype_id = \"{0}\"\n",
    "                     AND gene_chr = \"{1}\"\n",
    "                     AND gene_start BETWEEN {2} AND {3}\n",
    "                     \n",
    "                     UNION ALL\n",
    "                     \n",
    "                     SELECT * \n",
    "                     FROM gene_coordinates \n",
    "                     WHERE genotype_id = \"{0}\"\n",
    "                     AND gene_chr = \"{1}\"\n",
    "                     AND gene_start BETWEEN {2} AND {3}\n",
    "                     '''.format(genotype, chromsome, coordinate-distance, coordinate+distance), con)\n",
    "    # Should check why it returns the same row twice, probably need to correct the query\n",
    "    df = df.drop_duplicates()\n",
    "    df.insert(0, 'Query', pd.Series([\"_\".join([chromsome, str(coordinate)]) for x in range(len(df.index))]))\n",
    "    return(df)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for entity in [[\"Chr2\", 19681637], [\"Chr2\", 1234564], [\"Chr4\", 1234564], [\"Chr2\", 19681638]]:\n",
    "      df = pd.concat([df, get_SNP_neighbors(\"Arabidopsis\", entity[0], entity[1], 10000)])  \n",
    "#df.drop_duplicates(subset=[\"gene_id\"]).reset_index()\n",
    "#df1 = get_SNP_neighbors(\"Arabidopsis\", \"Chr2\", 19681637, 10000)\n",
    "#df1\n",
    "#pd.concat([df1, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find neighboring genes and annotate them\n",
    "\n",
    "df[\"annotation\"] = annotation_select(con, df[\"gene_id\"].to_list())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_available_species(con):\n",
    "    con = sqlite3.connect('SQNce.db')\n",
    "    cursorObj = con.cursor()\n",
    "    return(pd.read_sql_query(\"SELECT * FROM species\", con))\n",
    "\n",
    "show_available_species(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-practice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursorObj = con.cursor()\n",
    "cursorObj.execute('''SELECT gene_id, gene_annotation \n",
    "                     FROM gene_annotations \n",
    "                     WHERE gene_id =  ?  ''', (entity,))\n",
    "# (name,) - need the comma to treat it as a single item and not list of letters\n",
    "selected = cursorObj.fetchall()[0]\n",
    "od[selected[0]] = selected[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add documentation to SQNce queries\n",
    "\n",
    "def protein_seq_select(con, entity_list):\n",
    "    od = OrderedDict()\n",
    "    for entity in entity_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT protein_variant, gene_annotation \n",
    "                             FROM protein_seqs \n",
    "                             WHERE protein_variant =  ?  ''', (entity,))\n",
    "        # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "        selected = cursorObj.fetchall()[0]\n",
    "        record = SeqRecord(Seq(zlib.decompress(selected[1]).decode(encoding='UTF-8')), \n",
    "                           id=selected[0], name=\"\", description=\"\")\n",
    "        od[selected[0]] = record\n",
    "        with open(\"selected.fasta\", 'w') as handle:\n",
    "            SeqIO.write(od.values(), handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_select(con, entity_list):\n",
    "    ls = []\n",
    "    for entity in entity_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT gene_id, gene_annotation \n",
    "                             FROM gene_annotations \n",
    "                             WHERE gene_id =  ?  ''', (entity,))\n",
    "        # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "        selected = cursorObj.fetchall()\n",
    "        if selected == []:\n",
    "            ls.append(\"Gene not found\")\n",
    "        else:\n",
    "            ls.append(selected[0][1])    \n",
    "    return(ls)\n",
    "\n",
    "con = sqlite3.connect('SQNce.db')\n",
    "gene_list = [\"Zm00001d010294\", \"dsa\", \"Sobic.002G128101\", \"AT2G34360\", \"Sobic.002G128101\", \"002G128101\"]\n",
    "df = pd.DataFrame({\"name\": gene_list, \"annotation\": annotation_select(con, gene_list) })\n",
    "df.columns = [\"GeneID\", \"annotation\"]\n",
    "df\n",
    "#pd.DataFrame.from_dict(annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"], \"dict\"), \n",
    "#                       orient=\"index\", columns=[\"annotation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"]), \n",
    "                              orient=\"index\").reset_index()\n",
    "test.columns = [\"GeneID\", \"annotation\"]\n",
    "test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-student",
   "metadata": {},
   "source": [
    "# Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('SQNce.db')\n",
    "# Use the above query functions to parse SQNce with your gene lists \n",
    "input_value = [your_gene_list]\n",
    "protein_seq_select(con, input_value)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{ 'label': label, 'value': val} for label, val in [[1,2], [2,3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_db_vals(db, table, column, custom_vals=[], return_ls=False):\n",
    "    # Input is the column to select and from which table\n",
    "    # Returns a list of all values in a specific table from SQNce.db\n",
    "    # Custom vals are added to the front using nested list of [label, value]\n",
    "    ls = [{ 'label': label, 'value': val} for label, val in custom_vals]\n",
    "    con = sqlite3.connect(db) # deploy with this\n",
    "    cursorObj = con.cursor()\n",
    "    distinct_df = pd.read_sql_query('''SELECT DISTINCT {0} \n",
    "                                       FROM {1}'''.format(column, table), con)\n",
    "    if return_ls:\n",
    "            return(distinct_df[column].to_list())\n",
    "    for name in distinct_df[column]:\n",
    "        ls.append({'label': name, 'value': name})\n",
    "    return(ls)\n",
    "distinct_db_vals(\"SQNce.db\", \"gene_coordinates\", \"genotype_id\",[[1,2], [2,3]], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_gene_select(gene_list):\n",
    "    # Use an input list of genes to find their family assignments\n",
    "    con = sqlite3.connect(\"SQNce.db\")\n",
    "    ls = []\n",
    "    for gene in gene_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT protein_id, family_name \n",
    "                            FROM gene_families\n",
    "                            WHERE protein_id =  ? ''', (gene,))\n",
    "        selected = cursorObj.fetchall()\n",
    "        if selected == []:\n",
    "            ls.append(\"Gene not found\")\n",
    "        else:\n",
    "            ls.append(selected[0][1])    \n",
    "    return(ls)\n",
    "family_gene_select([\"Seita.5G010100\", \"test\", \"Zm00001d011673\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"SQNce.db\") # deploy with this\n",
    "cursorObj = con.cursor()\n",
    "genotype = str(\"','\".join(['Zea mays', \"dsa\",'Setaria italica']))\n",
    "family = str(\"','\".join(['Terpenoid synthases', 'Cytochrome P450']))\n",
    "df = pd.read_sql_query(\"\"\"SELECT protein_id, family_name \n",
    "                                   FROM gene_families\n",
    "                                   WHERE species_id IN ('{0}') AND family_name IN ('{1}')\"\"\".format(genotype, family), con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = \"subject_id\"\n",
    "entity_list = [\"Zm00001d014121\", \"Zm00001d014134, \"\"Zm00001d014136\"]\n",
    "con = sqlite3.connect(\"SQNce.db\") # deploy with this\n",
    "cursorObj = con.cursor()\n",
    "entity_list_str = str(\"','\".join(entity_list))\n",
    "df = pd.read_sql_query(\"\"\"SELECT * \n",
    "                        FROM BBHs\n",
    "                        WHERE {0} IN ('{1}')\"\"\".format(selected, entity_list_str), con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a stupid function but it seems to work correctly.\n",
    "df.sort_values(['bit_score'], ascending=False).groupby([\"subject_id\", \"query_genotype\"]).agg({\"bit_score\": \"first\", \"query_id\": \"first\",}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-throw",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df[\"query_genotype\"].isin([\"B97\", \"dsa\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(\"init/BBHs_combs.tsv\"), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-relative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
