{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlike-adelaide",
   "metadata": {},
   "source": [
    "# 1. Creation the SQNce-db file with all tables \n",
    "<a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "worst-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import sqlite3\n",
    "import zlib\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from Bio import SeqIO \n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "muslim-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "# Current implementation requires re-parsing of all the input files to create SQNce\n",
    "# TODO SQNce update functions to parse input data only if not previously included \n",
    "\n",
    "# Establish connection with SQNce.db, generating a new SQLite3 database if needed\n",
    "def sql_connection():\n",
    "    try:\n",
    "        con = sqlite3.connect('SQNce.db')\n",
    "        print(\"Connection established.\")\n",
    "        return(con)\n",
    "    except Error:\n",
    "        print(Error)\n",
    "\n",
    "# if os.path.exists(\"SQNce.db\"): os.remove(\"SQNce.db\")\n",
    "con = sql_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-exhibition",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "<a class=\"anchor\" id=\"section2\"></a>\n",
    "* [1. Creation the SQNce-db file with all tables](#section1)\n",
    "* [2. Populate SQNce-db with the required data](#section2)\n",
    "* [Insert GO Terms](#GO)\n",
    "* [Insert gene genomic coordinates](#coordinates)\n",
    "* [Insert protein sequences](#proteins)\n",
    "* [Insert gene family annotations](#families)\n",
    "* [Insert best blast hists (BBHs)](#BBHs)\n",
    "* [Insert OrthoFinder orthogroups](#orthogroups)\n",
    "* [Insert promoter sequences](#promoters)\n",
    "* [Gene annotation insert](#annotations)\n",
    "* [Insert gene symbols](#symbols)\n",
    "* [Insert RNA-seq Files](#RNAseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-sampling",
   "metadata": {},
   "source": [
    "# Description\n",
    "* SQNce database is initiated using predifined TSV files\n",
    "* TSV either contain the input data or reference input files to parse\n",
    "\n",
    "\n",
    "# To-do\n",
    "* Documentation and nomenclature\n",
    "* Standarize the column ids across the different tables\n",
    "* Add a 'force' option to overwrite existing table with new parsed data\n",
    "* Re-index columns if a table is updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-boating",
   "metadata": {},
   "source": [
    "# 2. Populate SQNce-db with the required data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-stress",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"GO\"></a>\n",
    "# Insert GO Terms\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the GO database OBO file to keep the GO annotations\n",
    "df = pd.read_csv(\"inputs/GO/go-basic.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df.columns = [\"GO_id\", \"GO_short\", \"process\", \"GO_long\"]\n",
    "df.to_sql('GO_basic', con, if_exists='replace', index=False)\n",
    "\n",
    "con.cursor().execute(\"CREATE INDEX GO_basic_id ON GO_basic(GO_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS genomes(\n",
    "                     genome_id text,\n",
    "                     species_name text,\n",
    "                     genotype_id text,\n",
    "                     source_id text,\n",
    "                     file_name text,\n",
    "                     gene_number integer)\"\"\")\n",
    "con.commit()\n",
    "\n",
    "df = pd.read_csv(\"init/genomes.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    \n",
    "    # Don't update update table if genome id already exists\n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM genomes WHERE genome_id =  ?''', (row[0],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "    \n",
    "    # If from phytozome use the annotation table to read number of genes\n",
    "        annot = pd.read_csv(\"inputs/annotations/\"+row[4], sep=\"\\t\")\n",
    "        annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "        con.cursor().execute(\"\"\"INSERT INTO genomes(\n",
    "                             genome_id, species_name, genotype_id,\n",
    "                             source_id, file_name, gene_number) \n",
    "                             VALUES(?, ?, ?, ?, ?, ?)\"\"\", row+[annot.shape[0]])\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_GOs(\n",
    "                     gene_id text, \n",
    "                     GO_id text, \n",
    "                     GO_count integer,\n",
    "                     genome_id text,\n",
    "                     source_id text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/GO_files.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    # Check annotation column\n",
    "    long_list = [] # have a row for each gene-GO combination\n",
    "    if row[3] == \"Phytozome\": # currently only support phytozome GO annotations\n",
    "        \n",
    "        # Don't update update table if genome id already exists\n",
    "        if con.cursor().execute('''SELECT COUNT(*) FROM gene_GOs WHERE genome_id =  ?  ''', (row[0],)).fetchall()[0][0]!=0:\n",
    "            continue\n",
    "\n",
    "        annot = pd.read_csv(\"inputs/annotations/\"+row[4], sep=\"\\t\")[['locusName', 'GO']]\n",
    "        # I am assuming that all variants have the same GO term but should double check\n",
    "        annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "        \n",
    "\n",
    "        # https://stackoverflow.com/questions/41244981/how-to-extract-comma-separated-values-to-individual-rows-in-pandas\n",
    "        annot = annot.set_index('locusName').GO.str.split(',', expand=True).stack().reset_index('locusName')\n",
    "        annot.columns = [\"gene_id\", \"GO\"]\n",
    "        annot = annot.merge(annot.groupby(\"GO\").count().reset_index(), on=\"GO\", how=\"left\")\n",
    "        annot[\"genome_id\"] = row[0]\n",
    "        annot[\"source_id\"] = row[3]\n",
    "\n",
    "        con.cursor().executemany(\"\"\"INSERT INTO gene_GOs(\n",
    "                                 gene_id, GO_id, GO_count, genome_id, source_id)  \n",
    "                                 VALUES(?,?,?,?,?)\"\"\", annot.values.tolist())\n",
    "con.commit()\n",
    "\n",
    "# Create a secondary key on the name column\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX IF NOT EXISTS gene_GOs_index_gene_id ON gene_GOs(gene_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-shore",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"coordinates\"></a>\n",
    "# Insert gene genomic coordinates\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_coordinates(\n",
    "                     gene_id text,\n",
    "                     genome_id text,\n",
    "                     gene_chr text,\n",
    "                     gene_start integer,\n",
    "                     gene_end integer,\n",
    "                     gene_orientation text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/coordinates.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    # Don't update update table if genome id already exists\n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM gene_coordinates WHERE genome_id =  ?  ''', (row[1],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "    \n",
    "    gff3_file = gzip.open(\"inputs/gff3/\"+row[3], mode='rt')\n",
    "    gene_coordinate_list = []\n",
    "    for gene in gff3_file:\n",
    "        gene = gene.split(\"\\t\")\n",
    "        if len(gene) == 1:\n",
    "            # skip the first row\n",
    "            continue\n",
    "        if gene[2] == \"gene\":\n",
    "            gene_id = gene[-1].split(\";\")\n",
    "            gene_id = [i for i in gene_id if i.startswith('Name=')][0].replace('Name=', '').replace('\\n', '') # delete \\n if exists\n",
    "            # Append list of: gene ID, genome_id, chromsome, start, end, orientation\n",
    "            gene_coordinate_list.append([gene_id, row[1], gene[0], gene[3], gene[4], gene[6]])\n",
    "        else:\n",
    "            continue\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_coordinates(\n",
    "                         gene_id, genome_id, gene_chr, \n",
    "                         gene_start, gene_end, gene_orientation) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", gene_coordinate_list)\n",
    "\n",
    "# Create a secondary key on the name column\n",
    "cursorObj = con.cursor()\n",
    "cursorObj.execute(\"CREATE INDEX IF NOT EXISTS coordinate_index_start ON gene_coordinates(genome_id, gene_chr, gene_start)\")\n",
    "cursorObj.execute(\"CREATE INDEX IF NOT EXISTS coordinate_index_end ON gene_coordinates(genome_id, gene_chr, gene_end)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-coalition",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"proteins\"></a>\n",
    "# Insert protein sequences\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS protein_seqs(\n",
    "                     protein_id text,\n",
    "                     species_id text,\n",
    "                     genome_id text,\n",
    "                     protein_length text,\n",
    "                     protein_sequence blob)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/proteins.tsv\", sep=\"\\t\")\n",
    "for row in df.items:\n",
    "    \n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM protein_seqs WHERE genome_id =  ?  ''', (row[0],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    fasta_file = gzip.open(\"inputs/proteins/\"+row[2], mode='rt')\n",
    "    protein_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        protein_seq_list.append([seq.id, row[0], row[1], len(seq.seq), \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO protein_seqs(\n",
    "                     protein_id, species_id, genome_id, \n",
    "                     protein_length, protein_sequence) \n",
    "                     VALUES(?, ?, ?, ?, ?)\"\"\", protein_seq_list)\n",
    "\n",
    "# Create keys for protein IDs with isoform and without\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS proteins_ids_index ON protein_seqs(protein_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-beverage",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"families\"></a>\n",
    "# Insert gene family annotations\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_families(\n",
    "                     protein_id text,\n",
    "                     genome_id text,\n",
    "                     source_id text,\n",
    "                     family_id text,\n",
    "                     family_name text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/families.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM gene_families WHERE genome_id =  ?  ''', (row[1],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "\n",
    "    annot = pd.read_csv(\"inputs/families/\"+row[3], sep=\"\\t\")\n",
    "    annot.insert(1, 'genome', row[1])\n",
    "    annot.insert(2, 'source', row[2])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_families(\n",
    "                         protein_id, genome_id,\n",
    "                         source_id, family_id, family_name) \n",
    "                         VALUES(?, ?, ?, ?, ?)\"\"\", annot.values.tolist())\n",
    "# Create keys for protein IDs with isoform and without\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS family_gene_index ON gene_families(protein_id)\")\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS family_name_index ON gene_families(family_name)\")\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS family_genotype_name_index ON gene_families(genome_id, family_name)\")\n",
    "con.commit()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-remove",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"BBHs\"></a>\n",
    "# Insert best blast hists (BBHs)\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS BBHs(\n",
    "                     subject_id text,\n",
    "                     query_id text,\n",
    "                     bit_score integer,\n",
    "                     subject_genome text,\n",
    "                     query_genome text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/BBHs_files.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    \n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM BBHs WHERE subject_genome =  ?  ''', (row[1],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "\n",
    "    bbh_df = pd.read_csv(\"inputs/BBHs/\"+row[2], sep=\"\\t\")\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO BBHs(\n",
    "                             subject_id, query_id, bit_score,\n",
    "                             subject_genome, query_genome) \n",
    "                             VALUES(?, ?, ?, ?, ?)\"\"\", bbh_df.values.tolist())\n",
    "\n",
    "# Create keys for subject and query gene IDs\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS BBHs_subject_index ON BBHs(subject_genome)\")\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS BBHs_query_index ON BBHs(query_genome)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-disposition",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"orthogroups\"></a>\n",
    "# Insert OrthoFinder orthogroups\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "economic-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"DROP TABLE IF EXISTS orthogroups\"\"\")\n",
    "con.commit()\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS orthogroups(\n",
    "                     orthogroup text,\n",
    "                     genome_id text,\n",
    "                     gene_id text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"inputs\",\"orthogroups\", \"Orthogroups.txt\"), sep=\"\\t\", index_col=0, low_memory=False)\n",
    "df = df.applymap(lambda x: x.split(\", \") if isinstance(x, str) else x)\n",
    "orth_list = []\n",
    "for col in df.columns:\n",
    "    for ix in df.index:\n",
    "        ls = df[col][ix]\n",
    "        if type(ls) != list:\n",
    "            continue\n",
    "        for l in ls:\n",
    "            orth_list.append([ix, col, l])\n",
    "\n",
    "con.cursor().executemany(\"\"\"INSERT INTO orthogroups(\n",
    "                         orthogroup, genome_id, gene_id) \n",
    "                         VALUES(?, ?, ?)\"\"\", orth_list)\n",
    "\n",
    "# Create keys for subject and query gene IDs\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS orthogroup_gene_ids ON orthogroups(gene_id)\")\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS orthogroup_gene_ids ON orthogroups(orthogroup)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-neighbor",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"promoters\"></a>\n",
    "# Insert promoter sequences\n",
    "\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS promoter_seqs(\n",
    "                     protein_id text,\n",
    "                     genome_id text,\n",
    "                     promoter_kind text,\n",
    "                     promoter_length text,\n",
    "                     promoter_sequence blob)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/promoters.tsv\", sep=\"\\t\")\n",
    "for row in df.values:\n",
    "    \n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM promoter_seqs WHERE genome_id =  ?  ''', (row[0],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "\n",
    "    fasta_file = gzip.open(\"inputs/promoters/\"+row[5]+\"_1kb_ATG.fasta.gz\", mode='rt')\n",
    "    promoter_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # TODO change db to number key to avoid duplicated name problems\n",
    "        if row[0] == \"ZmB73v3\": \n",
    "            seq.id = seq.id + \"v3\"\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        promoter_seq_list.append([seq.id, row[0], \"ATG\", row[4], \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO promoter_seqs(\n",
    "                             protein_id, genome_id, promoter_kind,\n",
    "                             promoter_length, promoter_sequence) \n",
    "                             VALUES(?, ?, ?, ?, ?)\"\"\", promoter_seq_list)\n",
    "    \n",
    "    fasta_file = gzip.open(\"inputs/promoters/\"+row[5]+\"_1kb_TSS.fasta.gz\", mode='rt')\n",
    "    promoter_seq_list = []\n",
    "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # TODO change db to number key to avoid duplicated name problems\n",
    "        if row[0] == \"ZmB73v3\": \n",
    "            seq.id = seq.id + \"v3\"\n",
    "        # Protein sequences are saved as as a Binary data type for compression\n",
    "        promoter_seq_list.append([seq.id, row[0], \"TSS\", row[4], \n",
    "                                 sqlite3.Binary(zlib.compress(str(seq.seq).encode('utf-8')))])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO promoter_seqs(\n",
    "                     protein_id, genome_id, promoter_kind,\n",
    "                     promoter_length, promoter_sequence) \n",
    "                     VALUES(?, ?, ?, ?, ?)\"\"\", promoter_seq_list)\n",
    "\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS promoter_index ON promoter_seqs(protein_id, promoter_kind)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-vienna",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"annotations\"></a>\n",
    "# Gene annotation insert\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_annotations(\n",
    "                     gene_id text,\n",
    "                     genome_id text,\n",
    "                     annotation_source text,\n",
    "                     gene_annotation text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/annotation_list.tsv\", sep=\"\\t\")\n",
    "\n",
    "for row in df.values:\n",
    "    \n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM gene_annotations WHERE genome_id =  ?  ''', (row[0],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    annot = pd.read_csv(\"inputs/annotations/\"+row[5], sep=\"\\t\")\n",
    "    annot = annot.drop_duplicates(subset=\"locusName\")\n",
    "\n",
    "    if row[1]==\"Arabidopsis thaliana\":\n",
    "        annot = annot[[\"locusName\", \"rice-defline\"]]\n",
    "    elif row[1] in [\"Panicum hallii\", \"Pharus latifolius\", \"Solanum lycopersicum\", \"Vigna unguiculata\"]:\n",
    "        annot = annot[[\"locusName\", \"Best-hit-arabi-defline\"]]        \n",
    "    else:\n",
    "        annot = annot[[\"locusName\", \"arabi-defline\"]]\n",
    "    annot.insert(1, 'genome_id', row[0])\n",
    "    annot.insert(2, 'source', row[4])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_annotations(\n",
    "                         gene_id, genome_id, annotation_source, gene_annotation) \n",
    "                         VALUES(?, ?, ?, ?)\"\"\", annot.values.tolist())\n",
    "\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS gene_annotations_index_gene_ids ON gene_annotations(gene_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-breakdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"symbols\"></a>\n",
    "# Insert gene symbols\n",
    "* [Go back to section 2](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS gene_symbols(\n",
    "                     gene_id text,\n",
    "                     genome_id text,\n",
    "                     gene_symbol text)\"\"\")\n",
    "\n",
    "df = pd.read_csv(\"init/symbols_list.tsv\", sep=\"\\t\")\n",
    "\n",
    "for row in df.values:\n",
    "    if con.cursor().execute('''SELECT COUNT(*) FROM gene_symbols WHERE genome_id =  ?  ''', (row[0],)).fetchall()[0][0]!=0:\n",
    "        continue\n",
    "\n",
    "    annot = pd.read_csv(\"inputs/symbols/\"+row[2], sep=\"\\t\")\n",
    "    annot.insert(1, 'gene_id', row[0])\n",
    "    con.cursor().executemany(\"\"\"INSERT INTO gene_symbols(\n",
    "                             gene_id, genome_id, gene_symbol) \n",
    "                             VALUES(?, ?, ?)\"\"\", annot.values.tolist())\n",
    "con.cursor().execute(\"CREATE INDEX IF NOT EXISTS gene_symbols_index_gene_ids ON gene_symbols(gene_id)\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-motor",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"RNAseq\"></a>\n",
    "# Insert RNA-seq Files\n",
    "* [Go back to section 2](#section2)\n",
    "\n",
    "(Note: This part will need more work and is not currently in use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS packages(\n",
    "                     rowid integer,\n",
    "                     name text,\n",
    "                     version text,\n",
    "                     settings text)\"\"\")\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS studies(\n",
    "                     study_accession text, \n",
    "                     tax_id integer,\n",
    "                     scientific_name text,\n",
    "                     instrument_model text,\n",
    "                     library_strategy text,\n",
    "                     description text)\"\"\")\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS fastq(\n",
    "                     run_accession text,\n",
    "                     study_accession text,\n",
    "                     read_count integer,\n",
    "                     sample_alias text,\n",
    "                     fastq_ftp text,\n",
    "                     fastq_md5 text,\n",
    "                     compression integer)\"\"\")\n",
    "\n",
    "con.cursor().execute(\"\"\"CREATE TABLE IF NOT EXISTS bam(\n",
    "                     run_accession text,\n",
    "                     study_accession text,\n",
    "                     sample_alias text,\n",
    "                     compression integer,\n",
    "                     filter integer,\n",
    "                     align integer,\n",
    "                     sort integer)\"\"\")\n",
    "\n",
    "def packages_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO packages(\n",
    "                         rowid, \n",
    "                         name,\n",
    "                         version,\n",
    "                         settings) \n",
    "                         VALUES(?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "    \n",
    "def studies_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO studies(\n",
    "                         study_accession, \n",
    "                         tax_id, \n",
    "                         scientific_name,\n",
    "                         instrument_model,\n",
    "                         library_strategy,\n",
    "                         description) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "\n",
    "# https://stackoverflow.com/questions/18219779/bulk-insert-huge-data-into-sqlite-using-python\n",
    "def fastq_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO fastq(\n",
    "                         run_accession, \n",
    "                         study_accession, \n",
    "                         read_count, \n",
    "                         sample_alias,  \n",
    "                         fastq_ftp,\n",
    "                         fastq_md5,\n",
    "                         compression) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "    \n",
    "def bam_insert(con, entities):\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\"\"\"INSERT INTO bam(\n",
    "                         run_accession,\n",
    "                         study_accession,\n",
    "                         sample_alias,\n",
    "                         compression,\n",
    "                         filter,\n",
    "                         align,\n",
    "                         sort) \n",
    "                         VALUES(?, ?, ?, ?, ?, ?, ?)\"\"\", entities)\n",
    "    con.commit()\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/packages.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    packages_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/studies.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    studies_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/fastq.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    fastq_insert(con, entities=list(row))\n",
    "\n",
    "df = pd.read_csv(\"inputs/omics/bam.tsv\", sep=\"\\t\")\n",
    "for index, row in df.iterrows():\n",
    "    bam_insert(con, entities=list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-resort",
   "metadata": {},
   "source": [
    "# SQNce Query Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-complaint",
   "metadata": {},
   "source": [
    "##### GO enrichment query and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import  hypergeom\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "rand_tps = [\"Zm00001d021929\",\"Zm00001d006678\",\"Zm00001d008370\",\"Zm00001d051416\",\"Zm00001d017540\",\"Zm00001d021410\",\n",
    "            \"Zm00001d026188\",\"Zm00001d034516\",\"Zm00001d035106\",\"Zm00001d036345\",\"Zm00001d033547\",\"Zm00001d035879\",\n",
    "            \"Zm00001d036080\",\"Zm00001d035881\",\"Zm00001d045909\",\"Zm00001d046750\",\"Zm00001d012394\",\"Zm00001d053084\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for entity in rand_tps:\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute('''SELECT gene_id, GO_id, GO_count \n",
    "                        FROM gene_GOs \n",
    "                        WHERE gene_id =  ?  ''', (entity,))\n",
    "    # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "    selected = cursorObj.fetchall()\n",
    "    if selected == []:\n",
    "        continue\n",
    "    else:\n",
    "        ls.append(selected[0])\n",
    "GO_df = pd.DataFrame(ls, columns=[\"gene_id\", \"GO_id\", \"GO_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursorObj = con.cursor()\n",
    "cursorObj.execute('''SELECT gene_number \n",
    "                    FROM genomes\n",
    "                    WHERE genome_id =  ?  ''', (\"ZmB73v4\",))\n",
    "# (name,) - need the comma to treat it as a single item and not list of letters\n",
    "selected = cursorObj.fetchall()\n",
    "genome_count = selected[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_geom(row):\n",
    "    hpd = hypergeom(row[2], row[1], row[3])\n",
    "    p = hpd.pmf(row[0])\n",
    "    return(p)\n",
    "\n",
    "GO_df = pd.DataFrame(ls, columns=[\"gene_id\", \"GO_id\", \"GO_count\"])\n",
    "GO_counts = GO_df.groupby(\"GO_id\").mean()[\"GO_count\"]\n",
    "GO_df = GO_df.groupby(\"GO_id\").count()\n",
    "GO_df[\"GO_count\"] = GO_counts\n",
    "GO_df[\"genome_count\"] = genome_count\n",
    "GO_df[\"group_count\"] = len(rand_tps)\n",
    "GO_df[\"pval\"] = GO_df.apply(hyper_geom, axis=1)\n",
    "GO_df[\"adj\"] = list(multipletests(GO_df[\"pval\"].values.tolist(), method=\"fdr_bh\")[1])\n",
    "GO_df[\"FC_enrichment\"] = (GO_df[\"gene_id\"] / GO_df[\"GO_count\"]) / (GO_df[\"group_count\"] / GO_df[\"genome_count\"])\n",
    "\n",
    "ls1 = []\n",
    "for entity in GO_df.index:\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute('''SELECT process, GO_short, GO_long \n",
    "                        FROM GO_basic\n",
    "                        WHERE GO_id =  ?  ''', (entity,))\n",
    "    # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "    selected = cursorObj.fetchall()\n",
    "    if selected == []:\n",
    "        continue\n",
    "    else:\n",
    "        ls1.append(selected[0])\n",
    "GO_basic = pd.DataFrame(ls1, columns=[\"process\", \"GO_short\", \"GO_long\"])\n",
    "GO_df = GO_df.reset_index()\n",
    "pd.concat([GO_df, GO_basic], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-funeral",
   "metadata": {},
   "source": [
    "##### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = \"\"\"Chr2\\t12345\\nChr3\\t54354\\nChr2\\t5234354\\n\"\"\".split(\"\\n\")\n",
    "coordinate_list = [row.split(\"\\t\") for row in rows]\n",
    "if coordinate_list[-1]==[\"\"]:\n",
    "    coordinate_list = coordinate_list[:-1]\n",
    "for row in coordinate_list:\n",
    "    if len(row) != 2:\n",
    "        return(html.P(\"Number of columns is not 2. Use tab-seperated values.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find neighboring genes\n",
    "def get_SNP_neighbors(genotype, chromsome, coordinate, distance):\n",
    "    con = sqlite3.connect('SQNce.db')\n",
    "    cursorObj = con.cursor()\n",
    "    df = pd.read_sql_query('''SELECT * \n",
    "                     FROM gene_coordinates \n",
    "                     WHERE genotype_id = \"{0}\"\n",
    "                     AND gene_chr = \"{1}\"\n",
    "                     AND gene_start BETWEEN {2} AND {3}\n",
    "                     \n",
    "                     UNION ALL\n",
    "                     \n",
    "                     SELECT * \n",
    "                     FROM gene_coordinates \n",
    "                     WHERE genotype_id = \"{0}\"\n",
    "                     AND gene_chr = \"{1}\"\n",
    "                     AND gene_start BETWEEN {2} AND {3}\n",
    "                     '''.format(genotype, chromsome, coordinate-distance, coordinate+distance), con)\n",
    "    # Should check why it returns the same row twice, probably need to correct the query\n",
    "    df = df.drop_duplicates()\n",
    "    df.insert(0, 'Query', pd.Series([\"_\".join([chromsome, str(coordinate)]) for x in range(len(df.index))]))\n",
    "    return(df)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for entity in [[\"Chr2\", 19681637], [\"Chr2\", 1234564], [\"Chr4\", 1234564], [\"Chr2\", 19681638]]:\n",
    "      df = pd.concat([df, get_SNP_neighbors(\"Arabidopsis\", entity[0], entity[1], 10000)])  \n",
    "#df.drop_duplicates(subset=[\"gene_id\"]).reset_index()\n",
    "#df1 = get_SNP_neighbors(\"Arabidopsis\", \"Chr2\", 19681637, 10000)\n",
    "#df1\n",
    "#pd.concat([df1, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find neighboring genes and annotate them\n",
    "\n",
    "df[\"annotation\"] = annotation_select(con, df[\"gene_id\"].to_list())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_available_species(con):\n",
    "    con = sqlite3.connect('SQNce.db')\n",
    "    cursorObj = con.cursor()\n",
    "    return(pd.read_sql_query(\"SELECT * FROM species\", con))\n",
    "\n",
    "show_available_species(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-import",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursorObj = con.cursor()\n",
    "cursorObj.execute('''SELECT gene_id, gene_annotation \n",
    "                     FROM gene_annotations \n",
    "                     WHERE gene_id =  ?  ''', (entity,))\n",
    "# (name,) - need the comma to treat it as a single item and not list of letters\n",
    "selected = cursorObj.fetchall()[0]\n",
    "od[selected[0]] = selected[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add documentation to SQNce queries\n",
    "\n",
    "def protein_seq_select(con, entity_list):\n",
    "    od = OrderedDict()\n",
    "    for entity in entity_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT protein_variant, gene_annotation \n",
    "                             FROM protein_seqs \n",
    "                             WHERE protein_variant =  ?  ''', (entity,))\n",
    "        # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "        selected = cursorObj.fetchall()[0]\n",
    "        record = SeqRecord(Seq(zlib.decompress(selected[1]).decode(encoding='UTF-8')), \n",
    "                           id=selected[0], name=\"\", description=\"\")\n",
    "        od[selected[0]] = record\n",
    "        with open(\"selected.fasta\", 'w') as handle:\n",
    "            SeqIO.write(od.values(), handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_select(con, entity_list):\n",
    "    ls = []\n",
    "    for entity in entity_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT gene_id, gene_annotation \n",
    "                             FROM gene_annotations \n",
    "                             WHERE gene_id =  ?  ''', (entity,))\n",
    "        # (name,) - need the comma to treat it as a single item and not list of letters\n",
    "        selected = cursorObj.fetchall()\n",
    "        if selected == []:\n",
    "            ls.append(\"Gene not found\")\n",
    "        else:\n",
    "            ls.append(selected[0][1])    \n",
    "    return(ls)\n",
    "\n",
    "con = sqlite3.connect('SQNce.db')\n",
    "gene_list = [\"Zm00001d010294\", \"dsa\", \"Sobic.002G128101\", \"AT2G34360\", \"Sobic.002G128101\", \"002G128101\"]\n",
    "df = pd.DataFrame({\"name\": gene_list, \"annotation\": annotation_select(con, gene_list) })\n",
    "df.columns = [\"GeneID\", \"annotation\"]\n",
    "df\n",
    "#pd.DataFrame.from_dict(annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"], \"dict\"), \n",
    "#                       orient=\"index\", columns=[\"annotation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(annotation_select(con, [\"Zm00001d010294\", \"Sobic.002G128101\", \"AT2G34360\"]), \n",
    "                              orient=\"index\").reset_index()\n",
    "test.columns = [\"GeneID\", \"annotation\"]\n",
    "test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-grenada",
   "metadata": {},
   "source": [
    "# Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('SQNce.db')\n",
    "# Use the above query functions to parse SQNce with your gene lists \n",
    "input_value = [your_gene_list]\n",
    "protein_seq_select(con, input_value)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{ 'label': label, 'value': val} for label, val in [[1,2], [2,3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_db_vals(db, table, column, custom_vals=[], return_ls=False):\n",
    "    # Input is the column to select and from which table\n",
    "    # Returns a list of all values in a specific table from SQNce.db\n",
    "    # Custom vals are added to the front using nested list of [label, value]\n",
    "    ls = [{ 'label': label, 'value': val} for label, val in custom_vals]\n",
    "    con = sqlite3.connect(db) # deploy with this\n",
    "    cursorObj = con.cursor()\n",
    "    distinct_df = pd.read_sql_query('''SELECT DISTINCT {0} \n",
    "                                       FROM {1}'''.format(column, table), con)\n",
    "    if return_ls:\n",
    "            return(distinct_df[column].to_list())\n",
    "    for name in distinct_df[column]:\n",
    "        ls.append({'label': name, 'value': name})\n",
    "    return(ls)\n",
    "distinct_db_vals(\"SQNce.db\", \"gene_coordinates\", \"genotype_id\",[[1,2], [2,3]], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_gene_select(gene_list):\n",
    "    # Use an input list of genes to find their family assignments\n",
    "    con = sqlite3.connect(\"SQNce.db\")\n",
    "    ls = []\n",
    "    for gene in gene_list:\n",
    "        cursorObj = con.cursor()\n",
    "        cursorObj.execute('''SELECT protein_id, family_name \n",
    "                            FROM gene_families\n",
    "                            WHERE protein_id =  ? ''', (gene,))\n",
    "        selected = cursorObj.fetchall()\n",
    "        if selected == []:\n",
    "            ls.append(\"Gene not found\")\n",
    "        else:\n",
    "            ls.append(selected[0][1])    \n",
    "    return(ls)\n",
    "family_gene_select([\"Seita.5G010100\", \"test\", \"Zm00001d011673\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"SQNce.db\") # deploy with this\n",
    "cursorObj = con.cursor()\n",
    "genotype = str(\"','\".join(['Zea mays', \"dsa\",'Setaria italica']))\n",
    "family = str(\"','\".join(['Terpenoid synthases', 'Cytochrome P450']))\n",
    "df = pd.read_sql_query(\"\"\"SELECT protein_id, family_name \n",
    "                                   FROM gene_families\n",
    "                                   WHERE species_id IN ('{0}') AND family_name IN ('{1}')\"\"\".format(genotype, family), con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = \"subject_id\"\n",
    "entity_list = [\"Zm00001d014121\", \"Zm00001d014134, \"\"Zm00001d014136\"]\n",
    "con = sqlite3.connect(\"SQNce.db\") # deploy with this\n",
    "cursorObj = con.cursor()\n",
    "entity_list_str = str(\"','\".join(entity_list))\n",
    "df = pd.read_sql_query(\"\"\"SELECT * \n",
    "                        FROM BBHs\n",
    "                        WHERE {0} IN ('{1}')\"\"\".format(selected, entity_list_str), con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a stupid function but it seems to work correctly.\n",
    "df.sort_values(['bit_score'], ascending=False).groupby([\"subject_id\", \"query_genotype\"]).agg({\"bit_score\": \"first\", \"query_id\": \"first\",}).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
