{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import io\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the diamonds DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = pd.read_csv(\"name_dictionary.csv\", index_col=0, sep=\"\\t\", header=None)\n",
    "fld = fld.to_dict()[1]\n",
    "fld[list(fld.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRHdb = pd.read_csv(\"BRHdb.csv\", index_col=None, sep=\"\\t\", header=0)\n",
    "# selected_list = BRHdb.names.unique()\n",
    "# BRHdb = BRHdb[BRHdb[\"name\"].isin([selected_list])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a diamond db for every fasta.gz file\n",
    "for fl in fld.keys():    \n",
    "    os.system(\"gunzip --keep --stdout files/{0} | \\\n",
    "               diamond makedb --in /dev/stdin --db dbs/{1}\".format(fld[fl], fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the gene list from the reference fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_gene_list(file_name):\n",
    "    \"\"\"\n",
    "    file_name: name of fa.gz file containing the amino-acid sequences of all genes\n",
    "               I ended up using the longest transcript files so might be simplified\n",
    "    \"\"\"\n",
    "    fasta_file = gzip.open(\"files/\"+file_name, mode='rt')\n",
    "    record_iterator = SeqIO.parse(fasta_file, \"fasta\")\n",
    "    od = OrderedDict()\n",
    "\n",
    "    for record in record_iterator:\n",
    "        record.id = str(record.id).split(\"_\")[0]\n",
    "        record.name = \"\"\n",
    "        record.description = \"\"\n",
    "        if record.id in od:\n",
    "            if len(record.seq) > len(od[record.id].seq):\n",
    "                od[record.id] = record\n",
    "        else:\n",
    "            od[record.id] = record\n",
    "\n",
    "    len(od.keys())\n",
    "    rbh_df = pd.DataFrame(index=od.keys())\n",
    "    return(rbh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_RBH(name, ref, qlist, fld):\n",
    "    \"\"\"\n",
    "    name:  the name of the output RBHdb\n",
    "    ref:   the name of the reference genome to be used \n",
    "    qlist: a list containing the query genomes to be used\n",
    "    fld:   a dictionary converting genome names to file names\n",
    "    \"\"\"\n",
    "    rbh_df = ref_gene_list(fld[ref])\n",
    "    # blast every non-reference fasta.gz file against the reference fasta.gz\n",
    "    for fl in qlist:\n",
    "        # Skip self-comparison if accidently included in the list\n",
    "        if fl == ref:\n",
    "            continue\n",
    "\n",
    "        # /dev/stdout only works if provided with permission: sudo chown -R $USER /dev\n",
    "        # Run Fwd comparison - ref vs. query\n",
    "        fwd = pd.read_csv(io.StringIO(subprocess.check_output(\"gunzip --keep --stdout files/{0} | \\\n",
    "                   diamond blastp --quiet -p 32 -d dbs/{1} -q /dev/stdin -o /dev/stdout \\\n",
    "                   --more-sensitive --outfmt 6 qseqid sseqid bitscore evalue\".format(fld[ref], fl),\n",
    "                   shell=True, text=True)), sep=\"\\t\", header=None)\n",
    "\n",
    "        # Run Reciprocal Rev comparison - query vs ref    \n",
    "        rev = pd.read_csv(io.StringIO(subprocess.check_output(\"gunzip --keep --stdout files/{0} | \\\n",
    "                   diamond blastp --quiet -p 32 -d dbs/{1} -q /dev/stdin -o /dev/stdout \\\n",
    "                   --more-sensitive --outfmt 6 qseqid sseqid bitscore evalue\".format(fld[fl], ref),\n",
    "                   shell=True, text=True)), sep=\"\\t\", header=None)\n",
    "\n",
    "        # Add headers to forward and reverse results dataframes\n",
    "        headers = [\"query\", \"subject\", \"bitscore\", \"evalue\"]\n",
    "        fwd.columns = headers\n",
    "        rev.columns = headers\n",
    "        \n",
    "        # RBH is defined as both Fwd and Rev are top ranked. Apply the following  \n",
    "        # Identicaly top ranks are < 2, so filtered for bitscore and then evalue\n",
    "        # If both values are identical, duplicate scores will be removed later\n",
    "        # https://stackoverflow.com/questions/54001339/drop-duplicates-but-keep-rows-with-highest-value-including-ties\n",
    "        fwd = fwd[fwd.groupby('query')['bitscore'].rank() < 2]\n",
    "        fwd = fwd[fwd.groupby('query')['evalue'].rank() < 2]\n",
    "        rev = rev[rev.groupby('query')['bitscore'].rank() < 2]\n",
    "        rev = rev[rev.groupby('query')['evalue'].rank() < 2]\n",
    "        \n",
    "        # Scores are no longer needed\n",
    "        fwd = fwd.drop(['bitscore', 'evalue'], axis=1)\n",
    "        rev = rev.drop(['bitscore', 'evalue'], axis=1)\n",
    "        \n",
    "        # TODO: make a separate category for top Blast hits \n",
    "        #       Can get a list of RBH gene IDs and drop them from blastp results? \n",
    "        \n",
    "        # https://widdowquinn.github.io/2018-03-06-ibioic/02-sequence_databases/05-blast_for_rbh.html\n",
    "        # Merge forward and reverse results\n",
    "        rbbh = pd.merge(fwd, rev[['query', 'subject']],\n",
    "                        left_on='subject', right_on='query', how='outer')\n",
    "\n",
    "        # Discard rows that are not RBH\n",
    "        rbbh = rbbh.loc[rbbh.query_x == rbbh.subject_y]\n",
    "\n",
    "        rbbh = rbbh.drop_duplicates(subset=[\"subject_y\"])\n",
    "\n",
    "        rbbh = rbbh.drop([\"query_y\", \"subject_y\"], axis=1)\n",
    "        rbbh.columns = [ref, fl]\n",
    "        rbbh = rbbh.set_index(ref)\n",
    "\n",
    "        # join the results with the main rbh_df\n",
    "        rbh_df = rbh_df.join(rbbh, how='outer')\n",
    "    \n",
    "    # Save the combined results as a csv file\n",
    "    rbh_df.to_csv(\"RBHs/RBH_\"+name+\".tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the BRHdb table to generate each individual RBHdb\n",
    "for name in BRHdb[\"name\"].unique():\n",
    "    ref = BRHdb[BRHdb[\"name\"].isin([name])][\"reference\"].unique()[0]\n",
    "    qlist = BRHdb[BRHdb[\"name\"].isin([name])][\"query\"].to_list()\n",
    "    print(\"Name:\", name, \"Ref:\", ref, \"Number of query genomes:\", len(qlist))\n",
    "    generate_RBH(name, ref, qlist, fld)\n",
    "\n",
    "os.system(\"for d in *.tsv ; do (gzip --keep $d); done\")\n",
    "os.system(\"mkdir zipped/\")\n",
    "os.system(\"for d in *.gz ; do (mv $d zipped/); done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
